{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226c2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e7f2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opencv_data/image/marathon_03.jpg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용할 모델 파일명\n",
    "model_name = 'opencv_data/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "# 알고리즘 구조를 정의한 파일\n",
    "protoextName = 'opencv_data/deploy.prototxt.txt'\n",
    "\n",
    "# 사용할 이미지\n",
    "# file_name = 'opencv_data/image/marathon_01.jpg'\n",
    "# file_name = 'opencv_data/image/marathon_02.jpg'\n",
    "file_name = 'opencv_data/image/marathon_03.jpg'\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f1c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 읽어온다.\n",
    "frame = cv2.imread(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e7f806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Net 0000022479C7DF90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용할 모델을 불러온다.\n",
    "model = cv2.dnn.readNetFromCaffe(protoextName, model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e27b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 변환한다.\n",
    "# 이 모델은 300x300 짜리 이미지 14만장을 학습한 이미지이기 때문에\n",
    "# 사이즈를 동일하게 맞춰줘야 한다.\n",
    "a1 = cv2.resize(frame, (300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27edd7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[151., 151., 151., ..., 151., 151., 151.],\n",
       "         [151., 151., 151., ..., 151., 151., 151.],\n",
       "         [148., 145., 147., ..., 150., 151., 151.],\n",
       "         ...,\n",
       "         [150., 150., 151., ..., 151., 148., 151.],\n",
       "         [151., 148., 146., ..., 149., 151., 151.],\n",
       "         [145., 149., 149., ..., 147., 148., 151.]],\n",
       "\n",
       "        [[ 77.,  77.,  78., ...,  78.,  78.,  78.],\n",
       "         [ 78.,  78.,  78., ...,  78.,  78.,  78.],\n",
       "         [ 78.,  75.,  76., ...,  77.,  78.,  78.],\n",
       "         ...,\n",
       "         [ 77.,  77.,  78., ...,  78.,  75.,  78.],\n",
       "         [ 78.,  75.,  73., ...,  76.,  78.,  78.],\n",
       "         [ 72.,  76.,  76., ...,  75.,  73.,  78.]],\n",
       "\n",
       "        [[132., 132., 132., ..., 132., 132., 132.],\n",
       "         [131., 131., 131., ..., 132., 132., 132.],\n",
       "         [130., 127., 129., ..., 131., 132., 132.],\n",
       "         ...,\n",
       "         [131., 131., 132., ..., 130., 131., 132.],\n",
       "         [132., 129., 127., ..., 130., 132., 132.],\n",
       "         [126., 130., 130., ..., 129., 126., 132.]]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2진 데이터로 변환한다.\n",
    "# 원본 이미지 데이터, 스케일링(크기조정), 결과 데이터 행렬 사이즈,\n",
    "# 표준화를 위해 기준이 되는 색상값\n",
    "blob = cv2.dnn.blobFromImage(a1, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f5ebb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 200, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 모델에 데이터를 넣어준다.\n",
    "model.setInput(blob)\n",
    "# 얼굴 부분을 인식한다.\n",
    "detections = model.forward()\n",
    "detections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "149c3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴이라고 인식되는 부분의 개수만큼 반복한다.\n",
    "# 결과의 3번째가 인식된 얼굴의 개수\n",
    "for i in range(0, detections.shape[2]) :\n",
    "    \n",
    "    # 얼굴이라고 인지한 정확도를 가져온다.\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    # print(confidence)\n",
    "    \n",
    "    # 확률이 높은 것만 표시한다.\n",
    "    if confidence > 0.2 :\n",
    "        # 얼굴이라고 인지된 부분을 모두 표시한다.\n",
    "\n",
    "        # 얼굴 부분 데이터를 가져온다.(이미지상의 비율)\n",
    "        box1 = detections[0, 0, i, 3:7]\n",
    "        # 원본 이미지에 맞게끔 좌표를 계산한다.\n",
    "        w1 = frame.shape[1]\n",
    "        h1 = frame.shape[0]\n",
    "        # box1은 좌측상단 x,y 우측하단 x,y 좌표 비율이기에\n",
    "        # 가로 세로길이를 곱해서 좌표를 환산한다.\n",
    "        box2 = box1 * np.array([w1, h1, w1, h1])\n",
    "\n",
    "        # 정수로 변환한다.\n",
    "        box3 = box2.astype('int')\n",
    "\n",
    "        # 네모를 그린다.\n",
    "        cv2.rectangle(frame, (box3[0], box3[1]), (box3[2], box3[3]), (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imshow('result', frame)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
