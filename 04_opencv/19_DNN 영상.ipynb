{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d866d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a05b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 모델 파일명\n",
    "model_name = 'opencv_data/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "# 모델 내의 신경망 구조 정보 파일명\n",
    "protoextName = 'opencv_data/deploy.prototxt.txt'\n",
    "# 파일 이름\n",
    "file_name = 'opencv_data/video/obama_01.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229b4024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Net 000001D29BD0EF10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용할 모델을 불러온다.\n",
    "model = cv2.dnn.readNetFromCaffe(protoextName, model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd9f773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영상 데이터를 가져온다.\n",
    "# cap = cv2.VideoCapture(file_name)\n",
    "\n",
    "#  카메라\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6bd919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True :\n",
    "    # 현재 프레임을 가져온다.\n",
    "    ret, frame = cap.read()\n",
    "    # 더 이상 프레임이 없다면 중단시킨다.\n",
    "    if frame is None :\n",
    "        break\n",
    "        \n",
    "    # 현재 프레임을 300x300으로 조정한다.\n",
    "    a1 = cv2.resize(frame, (300, 300))\n",
    "    # 2진 데이터로 변환한다.\n",
    "    blob = cv2.dnn.blobFromImage(a1, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    \n",
    "    # 데이터를 모델에 넣어준다.\n",
    "    model.setInput(blob)\n",
    "    # 얼굴을 인식한다.\n",
    "    detections = model.forward()\n",
    "    \n",
    "    # 인식된 얼굴의 수 만큼 반복한다.\n",
    "    for i in range(0, detections.shape[2]) :\n",
    "        # 얼굴임을 인식한 확률을 가져온다.\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        \n",
    "        if confidence > 0.5 :\n",
    "            # 원본 이미지 가로 세로 길이를 구한다.\n",
    "            width = frame.shape[1]\n",
    "            height = frame.shape[0]\n",
    "            \n",
    "            # 인식된 얼굴의 위치(비율)을 추출한다.\n",
    "            box1 = detections[0, 0, i, 3:7]\n",
    "            \n",
    "            # 비율을 실제 좌표로 계산한다.\n",
    "            box2 = box1 * np.array([width, height, width, height])\n",
    "            \n",
    "            # 정수값으로 변환한다.\n",
    "            box3 = box2.astype('int')\n",
    "            \n",
    "            # 네모를 그린다.\n",
    "            x1, y1, x2, y2 = box3\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    # 프레임을 그린다.\n",
    "    cv2.imshow('test', frame)\n",
    "    \n",
    "    # q 키를 누르면 중단한다.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') :\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd897804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
